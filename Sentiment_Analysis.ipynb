{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxIxaq8NWl_Q"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nPUeUybUY6u"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('./train.csv', delimiter=',')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1S9uHCNWtOy"
      },
      "source": [
        "# Playing with Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5te53iWbUht-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1479228-f65d-4409-fc5a-aeb4622ace3e"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI3mT4UDTCIX"
      },
      "source": [
        "The sentiment labels are:\n",
        "\n",
        "0 - negative\n",
        "1 - somewhat negative\n",
        "2 - neutral\n",
        "3 - somewhat positive\n",
        "4 - positive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LXbwBmwOTMUt",
        "outputId": "30923211-8eae-4f78-8f87-d6019dd35689"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FzL0Bm0Uxnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33026c59-9fb1-4f7e-a538-203544944f13"
      },
      "source": [
        "# Row count for each distinct Label\n",
        "dataset.Sentiment.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuiD9SAmW9h2"
      },
      "source": [
        "# Processing Text data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg09g-4FSySD"
      },
      "source": [
        "# Taking dataset[\"Phrase\"] and removing special characters,stopwords,\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZw-FdIRTmC4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size=0.25, random_state=5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3LQ0TrcXzlw"
      },
      "source": [
        "# Generating our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A2l1SdwnG97"
      },
      "source": [
        "## Multionomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn1NsV7XTw_E"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rpMfVm7Ty7M",
        "outputId": "8545dce4-f14c-48ef-f276-661b36d53a13"
      },
      "source": [
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ8k9lLTT19q"
      },
      "source": [
        "from sklearn import metrics\n",
        "predicted = MNB.predict(X_test)\n",
        "accuracy_score = metrics.accuracy_score(predicted, Y_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kPVhuxoUjW",
        "outputId": "26f75628-aa8d-4e38-8c6a-cd20186c4891"
      },
      "source": [
        "predicted"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 4, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lum24TdbrKYQ",
        "outputId": "08ddda10-769b-4050-e1c2-4f50930620b6"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<39015x14991 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 149694 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB9QqIeZqbXG"
      },
      "source": [
        "df2=pd.DataFrame(predicted,columns=['Label'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ukvR9VgIpWhW",
        "outputId": "06a15e0b-c399-46b3-e4c3-100343c5dcfe"
      },
      "source": [
        "df3=pd.concat([dataset['Phrase'],df2],axis=1,ignore_index=True)\n",
        "df3.drop_duplicates()\n",
        "df3.dropna()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A series</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>series</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39010</th>\n",
              "      <td>you do n't laugh</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39011</th>\n",
              "      <td>do n't laugh</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39012</th>\n",
              "      <td>, flee .</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39013</th>\n",
              "      <td>flee .</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39014</th>\n",
              "      <td>flee</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39015 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       0    1\n",
              "0      A series of escapades demonstrating the adage ...  2.0\n",
              "1      A series of escapades demonstrating the adage ...  2.0\n",
              "2                                               A series  2.0\n",
              "3                                                      A  3.0\n",
              "4                                                 series  2.0\n",
              "...                                                  ...  ...\n",
              "39010                                   you do n't laugh  2.0\n",
              "39011                                       do n't laugh  2.0\n",
              "39012                                           , flee .  4.0\n",
              "39013                                             flee .  0.0\n",
              "39014                                               flee  3.0\n",
              "\n",
              "[39015 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2o4oG6BT5I0",
        "outputId": "0fd06133-0c6c-4dcc-988b-22ec7d18fe51"
      },
      "source": [
        "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-L7aOecnZkw"
      },
      "source": [
        "### Using Bigram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1XEPsaCT7mh",
        "outputId": "8e46120f-9332-4c7b-847e-a371027bbefe"
      },
      "source": [
        "# using bigram\n",
        "\n",
        "cv = CountVectorizer(stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])\n",
        "\n",
        "#from sklearn.model_selection import train_test_split()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.25, random_state=5)\n",
        "\n",
        "\n",
        "#Fitting the model\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "\n",
        "#Evaulating the model\n",
        "#form sklearn import metrics\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
        "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlRXt7uJndyb"
      },
      "source": [
        "### Using trigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfmzb7LGUA-7",
        "outputId": "24a827ca-8995-4848-ec0f-de01ecf395db"
      },
      "source": [
        "\n",
        "cv = CountVectorizer(stop_words='english', ngram_range = (3,3), tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(dataset['Phrase'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.25, random_state=5)\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, Y_train)\n",
        "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
        "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38j11we6nwD4"
      },
      "source": [
        "## Complement Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRb4Lh_hUEvu",
        "outputId": "c04e1de7-34d7-44e9-b726-419894601c7e"
      },
      "source": [
        "\n",
        "#With this particular MNB model we are gaining success which is close to 60%, nomatter what n-gram vectorization we opt for.\n",
        "#Let's try to change the model to ComplementNB. \n",
        "\n",
        "#let's write the complete code assuming we have our data imported to dataset.\n",
        "\n",
        "#from sklearn.feature_extraction import CountVectorizer\n",
        "#from nlkt.tokenize import RegexpTokenizer\n",
        "#token = RegexpTokenixer(r'[A-Za-z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english', ngram_range=(1,1), tokenizer=token.tokenize)\n",
        "text_count = cv.fit_transform(dataset['Phrase'])\n",
        "\n",
        "#split the dataset in train test \n",
        "#form sklearn.model_selection() import train_test_split()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_count, dataset['Sentiment'], test_size=0.25, random_state=2)\n",
        "\n",
        "#Defining and compiling the model -> we will use ComplementNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "#Fitting the model\n",
        "CNB = ComplementNB()\n",
        "CNB.fit(X_train, Y_train)\n",
        "\n",
        "#evaluating the model\n",
        "#from sklearn import metrics\n",
        "accuracy_score = metrics.accuracy_score(CNB.predict(X_test),Y_test)\n",
        "\n",
        "print(str('{:4.2f}'.format(accuracy_score*100))+'%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47.53%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJbTVhF-UU3y"
      },
      "source": [
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# GNB = GaussianNB()\n",
        "# GNB.fit(X_train.todense(), Y_train)\n",
        "# accuracy_score = metrics.accuracy_score(CNB.predict(X_test),Y_test)\n",
        "\n",
        "# print('GNB accuracy = ' + str('{:4.2f}'.format(accuracy_score*100))+'%')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj1tAc-CjyE7"
      },
      "source": [
        "## Bernouli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ3quS1_UZa_",
        "outputId": "f6be2d96-b652-49a0-95c3-22da30fdac7d"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "BNB = BernoulliNB()\n",
        "BNB.fit(X_train, Y_train)\n",
        "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(X_test),Y_test)\n",
        "print('BNB accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BNB accuracy = 60.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILARVRZfUldG",
        "outputId": "8f401968-9436-480a-ad5a-6d574550db0f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "text_count_2 = tfidf.fit_transform(dataset['Phrase'])\n",
        "\n",
        "#splitting the data in test and training\n",
        "#from sklearn.model_selection() import train_test_split()\n",
        "x_train, x_test, y_train, y_test = train_test_split(text_count_2, dataset['Sentiment'],test_size=0.25,random_state=5)\n",
        "\n",
        "#defining the model\n",
        "#compilimg the model -> we are going to use already used models GNB, MNB, CNB, BNB\n",
        "#fitting the model\n",
        "MNB.fit(x_train, y_train)\n",
        "accuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\n",
        "print('accuracy_score_mnb = '+str('{:4.2f}'.format(accuracy_score_mnb*100))+'%')\n",
        "\n",
        "BNB.fit(x_train, y_train)\n",
        "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\n",
        "print('accuracy_score_bnb = '+str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n",
        "\n",
        "CNB.fit(x_train, y_train)\n",
        "accuracy_score_cnb = metrics.accuracy_score(CNB.predict(x_test), y_test)\n",
        "print('accuracy_score_cnb = '+str('{:4.2f}'.format(accuracy_score_cnb*100))+'%')\n",
        "\n",
        "# GNB.fit(x_train.todense(), y_train)\n",
        "# accuracy_score_gnb = metrics.accuracy_score(GNB.predict(x_test.todense()), y_test)\n",
        "# print('accuracy_score_gnb = '+str('{:4.2f}'.format(accuracy_score_gnb*100))+'%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score_mnb = 58.50%\n",
            "accuracy_score_bnb = 59.33%\n",
            "accuracy_score_cnb = 51.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImYYLrJfn-ay"
      },
      "source": [
        "# Using Non Naive Bayes classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i33kdeEVma2",
        "outputId": "7e6cd292-c0c5-4e0c-9596-1bdfc4170354"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "SGDC = SGDClassifier()\n",
        "LSVC = LinearSVC()\n",
        "\n",
        "#on TF-IDF data\n",
        "LSVC.fit(x_train, y_train)\n",
        "accuracy_score_lsvc = metrics.accuracy_score(LSVC.predict(x_test), y_test)\n",
        "print('accuracy_score_lsvc = '+str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')\n",
        "\n",
        "SGDC.fit(x_train, y_train)\n",
        "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
        "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
        "\n",
        "#on CountVectorize data\n",
        "LSVC.fit(X_train, Y_train)\n",
        "accuracy_score_lsvc_CV = metrics.accuracy_score(LSVC.predict(X_test), Y_test)\n",
        "print('accuracy_score_lsvc_cv = '+str('{:4.2f}'.format(accuracy_score_lsvc_CV*100))+'%')\n",
        "\n",
        "SGDC.fit(X_train, Y_train)\n",
        "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(X_test), Y_test)\n",
        "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score_lsvc = 63.88%\n",
            "accuracy_score_sgdc = 56.41%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy_score_lsvc_cv = 63.05%\n",
            "accuracy_score_sgdc_cv = 60.31%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}